YOLO mode is enabled. All tool calls will be automatically approved.
YOLO mode is enabled. All tool calls will be automatically approved.
I will examine the current Jupyter notebook to understand its structure before optimizing it for parallel execution.
I will now update the Jupyter notebook to use `concurrent.futures.ThreadPoolExecutor` for fetching the pages in parallel, and then execute it using `jupyter nbconvert`.
I will now write the optimized notebook containing the parallelized fetching logic using `ThreadPoolExecutor`.
I will now execute the updated notebook to verify the execution time is under the 4-second limit and the CSV file is generated correctly.
I'll verify the generated `expression_data.csv` file has exactly 200 rows and the right columns.
I will quickly verify the execution time reported in the notebook to confirm it is within the 4-second limit.
I have successfully optimized the Jupyter notebook for parallel execution and verified the results.

### Summary of Changes:
1. **Parallel Execution**: Replaced the sequential `for` loop with `concurrent.futures.ThreadPoolExecutor` to fetch the 20 pages concurrently. Since each request is I/O-bound (taking ~0.5s), launching all 20 threads simultaneously completes the data collection in ~0.5s overall.
2. **Data Combination**: Gathered the results from `executor.map` and extended them into a single list before converting to a pandas DataFrame.
3. **Data Formatting**: Enforced the column order strictly (`gene_id`, `expression_level`, `sample_id`), sorted the DataFrame by `gene_id` in ascending order, and saved it to `/home/user/expression_data.csv` without an index.
4. **Validation**: Ran the notebook using the requested `jupyter nbconvert --to notebook --execute` command. The execution finished in just ~0.51 seconds (well below the 3-4 second threshold), and successfully saved precisely 200 formatted records to the CSV output.
