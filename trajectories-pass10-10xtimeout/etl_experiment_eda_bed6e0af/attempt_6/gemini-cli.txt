YOLO mode is enabled. All tool calls will be automatically approved.
YOLO mode is enabled. All tool calls will be automatically approved.
I have successfully created and verified the ETL pipeline Jupyter notebook as requested.

The notebook `/home/user/etl_experiment_eda.ipynb` has been fully developed with the requested steps:
1. **Load and Merge**: Loads the raw datasets (`plot_metadata.csv` and `yield_data.csv`) and performs an inner join on `plot_id`. I've added safety parsing logic (`fillna("None")`) so that any default pandas parsing of `"None"` correctly registers as a proper fertilizer label rather than missing data.
2. **Clean Anomaly Data**: Filters out rows with invalid environmental conditions by keeping only records where `daily_temp <= 50` and `daily_rainfall >= 0`.
3. **Summary Statistics**: Groups by `fertilizer` to compute the mean of `yield_kg` and `daily_temp`. It automatically exports these float values directly into `/home/user/summary_stats.json` in the specified dictionary format.
4. **Data Visualization**: Generates a scatter plot comparing `daily_temp` (x-axis) and `yield_kg` (y-axis) and saves it locally as `/home/user/temp_vs_yield.png`. 
5. **Clean Data Export**: Saves the resultant filtered DataFrame to `/home/user/clean_experiment_data.csv` (including headers but without the index).
6. **Validation Cells**: At the end of the notebook, an automated set of Python `assert` tests verify the conditions on `clean_experiment_data.csv` (i.e. exactly 8 valid rows, max `daily_temp` $\le$ 50, and min `daily_rainfall` $\ge$ 0).

I ran `jupyter nbconvert --to notebook --execute /home/user/etl_experiment_eda.ipynb` via my shell commands to empirically test the pipeline from top-to-bottom on dummy dataset mockups, and all automated logic, outputs, and assert validations succeeded successfully.
