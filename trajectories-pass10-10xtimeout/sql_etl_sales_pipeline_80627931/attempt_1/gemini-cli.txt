YOLO mode is enabled. All tool calls will be automatically approved.
YOLO mode is enabled. All tool calls will be automatically approved.
I will create the Jupyter Notebook file at `/home/user/etl_pipeline.ipynb` with the specified steps and SQL query to process the data and save it.

I will verify that the notebook executes properly by running the automated test command provided.
I'll use Python to build and save the notebook properly to avoid any JSON encoding issues.
I will run the automated test command again to ensure the newly formatted notebook executes without errors.
I'll check the generated `clean_sales.csv` to verify its contents meet your requirements.
I have successfully created the ETL pipeline Jupyter Notebook at `/home/user/etl_pipeline.ipynb` and verified its execution.

The notebook performs all the required steps:
1. Imports `pandas` and `sqlite3`.
2. Loads `/home/user/raw_sales.csv`.
3. Loads the data into an in-memory SQLite database under the table `sales`.
4. Executes the SQL query using `SUM` and the `RANK()` window function to calculate `total_revenue` and `sales_rank` per `region`.
5. Outputs the result seamlessly to `/home/user/clean_sales.csv` without the pandas index.

I've also run the automated `jupyter nbconvert` test on the notebook, and it executes cleanly from top to bottom, generating the correct output in `/home/user/clean_sales.csv`.
